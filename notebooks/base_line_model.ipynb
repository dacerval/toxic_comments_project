{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cdc05517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0de5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35c5eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is the index unique : True\n"
     ]
    }
   ],
   "source": [
    "print('is the index unique :' ,dftrain.id.is_unique)\n",
    "dftrain.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff5be427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.severe_toxic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27379f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest=pd.read_csv('test.csv')\n",
    "dftest_labels=pd.read_csv('test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58744006",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest.set_index('id', inplace = True)\n",
    "dftest_labels.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e86aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labes_validity = (dftest_labels == -1).sum(axis=1)\n",
    "valid_labels_id =labes_validity[labes_validity ==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb52c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest_valid=dftest[dftest.index.isin(valid_labels_id)]\n",
    "dftest_labels_valid =  dftest_labels[dftest_labels.index.isin(valid_labels_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ccf230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape (63978, 6)\n",
      "test data shape  (63978, 1)\n"
     ]
    }
   ],
   "source": [
    "print('labels shape', dftest_labels_valid.shape)\n",
    "print('test data shape ', dftest_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadc873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.severe_toxic.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4eeba",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a523ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16589e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bow=CountVectorizer(max_features= 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ed31c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=8000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_bow.fit(dftrain.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af16dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer_bow.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfa81d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform documents to document-term matrix.\n",
    "vector_bow=vectorizer_bow.transform(dftrain.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6138e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_test_bow = vectorizer_bow.transform(dftest_valid.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a07d49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vector_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3a2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88404b",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09b15283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48caab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d3531b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and build vocab\n",
    "vectorizer_tfidf.fit(dftrain.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65e37c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tdfidf=vectorizer_tfidf.transform(dftrain.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0ed751",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_test_tfdfidf=vectorizer_tfidf.transform(dftest_valid.comment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bda34c",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cde5840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dftrain.loc[:, ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "751e309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7d4e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98b0df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(vector_bow, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd81073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8926349682703429"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vector_test_bow, dftest_labels_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8374ac",
   "metadata": {},
   "source": [
    "### Training with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cff12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 1e+03 ns, total: 32 µs\n",
      "Wall time: 43.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6ca10dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 15s, sys: 5.6 s, total: 22min 21s\n",
      "Wall time: 43min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(vector_tdfidf, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f451a125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8817718590765575"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vector_test_tfdfidf, dftest_labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e8194d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 44.3 ms, total: 11 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_tf_idf = clf.predict(vector_test_tfdfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "187dec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual toxic 6090\n",
      "predicted as toxic 3049\n",
      "recall  0.5006568144499179\n"
     ]
    }
   ],
   "source": [
    "pred_toxic=pd.Series(y_pred_tf_idf[:,0], index=dftest_labels_valid.index)\n",
    "pred_toxic.name = 'pred_toxic'\n",
    "results_vs_pred=pd.concat([pred_toxic,dftest_labels_valid.toxic], axis=1)\n",
    "\n",
    "results_vs_pred['is_correct']=results_vs_pred.apply(lambda row: True if row['pred_toxic'] ==  row['toxic'] \n",
    "                                                    else False, axis=1)\n",
    "print('actual toxic', results_vs_pred.toxic.sum())\n",
    "print('predicted as toxic', results_vs_pred[results_vs_pred.toxic == True].is_correct.sum())\n",
    "print('recall ', results_vs_pred[results_vs_pred.toxic == True].is_correct.sum()/results_vs_pred.toxic.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2253e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual severe toxic  367\n",
      "predicted as toxic  66\n",
      "recall  0.035422343324250684\n"
     ]
    }
   ],
   "source": [
    "pred_severe_toxic=pd.Series(y_pred_tf_idf[:,1], index=dftest_labels_valid.index)\n",
    "pred_severe_toxic.name = 'pred_severe_toxic'\n",
    "results_vs_pred_severetoxic=pd.concat([pred_severe_toxic, dftest_labels_valid.severe_toxic], axis=1)\n",
    "results_vs_pred_severetoxic['is_correct']=results_vs_pred_severetoxic.apply(lambda row: True if row['severe_toxic'] ==row['pred_severe_toxic'] else False,\n",
    "                                 axis=1)\n",
    "\n",
    "print('actual severe toxic ', (results_vs_pred_severetoxic.severe_toxic==1).sum())\n",
    "print('predicted as toxic ', pred_severe_toxic.sum())\n",
    "print('recall ', ((results_vs_pred_severetoxic.severe_toxic==1) & (results_vs_pred_severetoxic.is_correct ==\n",
    "                                                  True)).sum()/(results_vs_pred_severetoxic.severe_toxic==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7cf3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypred_tf_idf=pd.DataFrame(y_pred_tf_idf, columns=list(dftest_labels_valid.columns))\n",
    "df_ypred_tf_idf.apply(lambda x: x.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e8e08d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.55      0.50      0.53      6090\n",
      " severe_toxic       0.20      0.04      0.06       367\n",
      "      obscene       0.48      0.45      0.47      3691\n",
      "       threat       0.42      0.02      0.04       211\n",
      "       insult       0.81      0.29      0.43      3427\n",
      "identity_hate       0.74      0.04      0.08       712\n",
      "\n",
      "    micro avg       0.56      0.40      0.46     14498\n",
      "    macro avg       0.53      0.22      0.27     14498\n",
      " weighted avg       0.59      0.40      0.45     14498\n",
      "  samples avg       0.05      0.04      0.04     14498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dftest_labels_valid.to_numpy(), y_pred_tf_idf,\n",
    "                            target_names=list(dftest_labels_valid.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c0ae2e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mayracervantes/Documentsmac/DataScience/projects/toxic_comments/data'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c47ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
